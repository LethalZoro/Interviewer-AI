{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EY6lXGnhM_jz",
        "outputId": "42aa71c5-cd0b-449b-d94f-3c593d0f285f"
      },
      "outputs": [],
      "source": [
        "# !pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wfFF2vI6M_Wr",
        "outputId": "a87aa1a6-9246-4ce5-eec6-6be5287d1663"
      },
      "outputs": [],
      "source": [
        "# !pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install elevenlabs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3rL8A-c8Mvgh",
        "outputId": "e90f5435-1674-490d-e5d2-348e340a1eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An error occurred: no such file: 'Resume Awias.pdf'\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import fitz  # PyMuPDF for PDF handling\n",
        "import json\n",
        "\n",
        "# Initialize OpenAI API key\n",
        "openai.api_key = \"\" \n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as pdf:\n",
        "        for page_num in range(pdf.page_count):\n",
        "            page = pdf[page_num]\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Function to generate a CV summary and identify skills\n",
        "def generate_cv_summary_and_identify_skills(cv_text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an HR assistant summarizing a CV for interview preparation.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize the following CV and identify key skills and expertise areas:\\n\\n{cv_text}\"}\n",
        "        ],\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    summary = response.choices[0].message['content'].strip()\n",
        "\n",
        "    # Extract skills\n",
        "    skills_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a system identifying the main skills for interview questions.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Based on this CV summary:\\n\\n{summary}\\n\\nList main skills.\"}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    skills = skills_response.choices[0].message['content'].strip()\n",
        "    return summary, skills.splitlines()\n",
        "\n",
        "# Function to generate progressively difficult questions based on skills and job description\n",
        "def generate_questions_by_skill(skill, job_description):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an HR assistant creating interview questions for a specific skill aligned with a job description.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Using the job description:\\n\\n{job_description}\\n\\nGenerate a basic, intermediate, and advanced interview question for the skill '{skill}'. Format the questions as a JSON object with keys 'basic', 'intermediate', and 'advanced'.\"}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    questions_text = response.choices[0].message['content'].strip()\n",
        "\n",
        "    try:\n",
        "        questions = json.loads(questions_text)  # Parse JSON into a Python dictionary\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not parse JSON for skill '{skill}'. Response text:\\n{questions_text}\")\n",
        "        questions = None\n",
        "\n",
        "    return questions\n",
        "\n",
        "# Function to generate 12 unique questions for the interview\n",
        "def generate_unique_questions(cv_summary, skills, job_description):\n",
        "    questions = []\n",
        "    seen_questions = set()\n",
        "\n",
        "    for skill in skills:\n",
        "        skill_questions = generate_questions_by_skill(skill, job_description)\n",
        "        if skill_questions:\n",
        "            for level in ['basic', 'intermediate', 'advanced']:\n",
        "                question = skill_questions.get(level)\n",
        "                if question and question not in seen_questions:\n",
        "                    questions.append({\"skill\": skill, \"level\": level, \"question\": question})\n",
        "                    seen_questions.add(question)\n",
        "                if len(questions) == 12:\n",
        "                    break\n",
        "        if len(questions) == 12:\n",
        "            break\n",
        "\n",
        "    return questions\n",
        "\n",
        "# Function to evaluate candidate answers based on the CV summary\n",
        "def evaluate_answer(answer, expected_topic):\n",
        "    evaluation_prompt = f\"Evaluate the following answer based on the topic '{expected_topic}' from the CV summary. Does it align well with the expected expertise? Answer: {answer}\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an HR assistant providing a score and feedback for the candidate's answer.\"},\n",
        "            {\"role\": \"user\", \"content\": evaluation_prompt}\n",
        "        ],\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    feedback = response.choices[0].message['content'].strip()\n",
        "\n",
        "    return feedback\n",
        "\n",
        "# Function to generate a formatted performance report\n",
        "def generate_formatted_performance_report(result_card):\n",
        "    performance_data = json.dumps(result_card, indent=2)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Using the following interview result data:\n",
        "\n",
        "{performance_data}\n",
        "\n",
        "Generate a summary in the following format:\n",
        "\n",
        "Overall Result: X out of 12 points (Y%).\n",
        "\n",
        "Strengths:\n",
        "\n",
        "[Skill Area (Basic/Intermediate/Advanced):]\n",
        "\n",
        "• Bullet point 1.\n",
        "• Bullet point 2.\n",
        "• Bullet point 3.\n",
        "\n",
        "Weaknesses:\n",
        "\n",
        "[Skill Area:]\n",
        "\n",
        "• Bullet point 1.\n",
        "• Bullet point 2.\n",
        "• Bullet point 3.\n",
        "\n",
        "Conclusion: A concise conclusion summarizing strengths and weaknesses.\n",
        "\"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an HR assistant generating a formatted performance report based on interview results.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "# Function to conduct an interactive interview\n",
        "def conduct_interactive_interview(questions, cv_summary):\n",
        "    interview_responses = []\n",
        "    total_score = 0\n",
        "\n",
        "    print(\"Bot: Welcome to the interview assistant.\")\n",
        "    print(\"Bot: Let's start with a few casual questions to get to know you better.\")\n",
        "\n",
        "    name = input(\"Bot: What is your name? \").strip()\n",
        "    location = input(f\"Bot: Nice to meet you, {name}! Where are you currently located? \").strip()\n",
        "    hobbies = input(\"Bot: That's great! What are some of your hobbies? \").strip()\n",
        "\n",
        "    print(\"\\nBot: Thank you for sharing! Now let's move to the interview questions.\\n\")\n",
        "\n",
        "    for i, q in enumerate(questions):\n",
        "        print(f\"Question {i + 1} ({q['level'].capitalize()} - {q['skill']}): {q['question']}\")\n",
        "        candidate_response = input(\"Your Answer: \").strip()\n",
        "\n",
        "        if candidate_response.lower() == \"quit\":\n",
        "            print(\"Bot: Interview ended. Thank you for your time!\")\n",
        "            break\n",
        "\n",
        "        feedback = evaluate_answer(candidate_response, q['skill'])\n",
        "\n",
        "        interview_responses.append({\n",
        "            \"skill\": q['skill'],\n",
        "            \"level\": q['level'],\n",
        "            \"question\": q['question'],\n",
        "            \"answer\": candidate_response,\n",
        "            \"feedback\": feedback\n",
        "        })\n",
        "\n",
        "        if \"good\" in feedback or \"excellent\" in feedback:\n",
        "            total_score += 1\n",
        "        elif \"average\" in feedback:\n",
        "            total_score += 0.5\n",
        "\n",
        "    score_percentage = (total_score / 12) * 100\n",
        "\n",
        "    result_card = {\n",
        "        \"total_score\": total_score,\n",
        "        \"score_percentage\": score_percentage,\n",
        "        \"feedback\": interview_responses\n",
        "    }\n",
        "\n",
        "    print(\"\\nInterview Complete. Generating Performance Report...\\n\")\n",
        "\n",
        "    # Generate and display the formatted performance report\n",
        "    report = generate_formatted_performance_report(result_card)\n",
        "    print(report)\n",
        "\n",
        "    # Save the report to a file\n",
        "    with open(\"Formatted_Performance_Report.txt\", \"w\") as file:\n",
        "        file.write(report)\n",
        "    print(\"\\nFormatted Performance Report saved to 'Formatted_Performance_Report.txt'.\")\n",
        "\n",
        "    return result_card\n",
        "\n",
        "# Main function to conduct the entire interview process\n",
        "def full_interview_process():\n",
        "    cv_pdf_path = \"Resume Awias.pdf\"  # Replace with the actual CV file path\n",
        "    job_pdf_path = \"AI Job Post.pdf\"  # Replace with the actual Job Description file path\n",
        "\n",
        "    try:\n",
        "        cv_text = extract_text_from_pdf(cv_pdf_path)\n",
        "        job_description = extract_text_from_pdf(job_pdf_path)\n",
        "\n",
        "        cv_summary, skills = generate_cv_summary_and_identify_skills(cv_text)\n",
        "        print(\"\\nDetailed CV Summary:\\n\", cv_summary)\n",
        "\n",
        "        questions = generate_unique_questions(cv_summary, skills, job_description)\n",
        "\n",
        "        if questions:\n",
        "            conduct_interactive_interview(questions, cv_summary)\n",
        "        else:\n",
        "            print(\"Interview could not proceed due to issues in question generation.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Run the full interview process\n",
        "if __name__ == \"__main__\":\n",
        "    full_interview_process()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "from io import BytesIO\n",
        "from elevenlabs.client import ElevenLabs\n",
        "\n",
        "def text_to_speech(text):\n",
        "    client = ElevenLabs(\n",
        "    api_key='sk_2b3fd08d38c7744e307ea42db37b8b9529f46f94424737e8',\n",
        "    )\n",
        "    # Get streamed audio\n",
        "    audio_stream = client.text_to_speech.convert_as_stream(\n",
        "        text=text,\n",
        "        voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
        "        model_id=\"eleven_multilingual_v2\"\n",
        "    )\n",
        "\n",
        "    # Collect the audio bytes\n",
        "    audio_bytes = b\"\".join(chunk for chunk in audio_stream if isinstance(chunk, bytes))\n",
        "\n",
        "    # Convert to an AudioSegment\n",
        "    audio_segment = AudioSegment.from_file(BytesIO(audio_bytes), format=\"mp3\")\n",
        "\n",
        "    # Play the audio\n",
        "    play(audio_segment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "import pyaudio\n",
        "\n",
        "def speech_to_text():   \n",
        "    mic_index = 3  # Replace with the correct index from the list\n",
        "\n",
        "    init_rec = sr.Recognizer()\n",
        "    with sr.Microphone(device_index=mic_index) as source:\n",
        "        print(\"Adjusting to ambient noise...\")\n",
        "        init_rec.adjust_for_ambient_noise(source, duration=1)  # Adjust for noise\n",
        "        print(\"Start Speaking Listening...\")\n",
        "        audio_data = init_rec.listen(source)\n",
        "        \n",
        "    try:\n",
        "        text = init_rec.recognize_google(audio_data)\n",
        "        print(\"You said:\", text)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Sorry, could not understand the audio.\")\n",
        "    except sr.RequestError:\n",
        "        print(\"Could not request results. Check your internet connection.\")\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "EarhUnHkc0kA",
        "outputId": "4f80cbc5-6b27-4cd6-94fa-2426d28270cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detailed CV Summary:\n",
            " Sheheryar Ramzan is a Computer Science student with a GPA of 3.51/4.00 from FAST National University. He has expertise in areas such as Artificial Intelligence, Machine Learning, Deep Learning, Computer Vision, and Generative AI. Key skills include Python programming, TensorFlow, Keras, PyTorch, Scikit-learn, OpenCV, and Numpy. Sheheryar has experience in algorithm engineering, machine learning, and teaching assistance. He has worked on projects related to cricket shot analysis, contraband detection, Parkinson's disease classification, and more. Sheheryar also has certifications in Generative AI and Neural Networks and has received awards for academic excellence.\n",
            "Bot: Welcome to the interview assistant.\n",
            "Bot: Let's start with a few casual questions to get to know you better.\n",
            "\n",
            "Bot: Before we begin the interview, I need to collect some important information.\n",
            "\n",
            "Bot: Please provide the following information for freelance/consulting work:\n",
            "\n",
            "Bot: Thank you for sharing! Now let's move to the interview questions.\n",
            "\n",
            "Question 1 (Basic - Based on the CV summary provided, the main skills of Sheheryar Ramzan are:): Can you briefly explain the main skills listed on your CV summary related to machine learning and data science?\n",
            "Question 2 (Intermediate - Based on the CV summary provided, the main skills of Sheheryar Ramzan are:): How have you utilized your main skills in machine learning and data science to solve complex problems in your previous projects or work experiences?\n",
            "Question 3 (Advanced - Based on the CV summary provided, the main skills of Sheheryar Ramzan are:): Can you provide a detailed example of a project where you successfully applied advanced machine learning techniques such as deep learning architectures like CNNs, RNNs, Transformers, or GANs? How did these techniques contribute to the project's success?\n",
            "Question 4 (Basic - ): Can you explain the difference between supervised and unsupervised learning techniques?\n",
            "Question 5 (Intermediate - ): How would you go about optimizing a machine learning model for performance, scalability, and interpretability?\n",
            "Bot: Interview ended. Thank you for your time!\n",
            "\n",
            "Interview Complete. Generating Performance Report...\n",
            "\n",
            "```plaintext\n",
            "Pre-Interview Conditions:\n",
            "Employment Type: Freelance/Consulting\n",
            "Availability: 50%\n",
            "Remote Rate: $50/hour\n",
            "On-site Rate: $34/hour\n",
            "Willing to Travel: yes\n",
            "Other Details: no\n",
            "\n",
            "Overall Result: 3 out of 12 points (25%).\n",
            "\n",
            "Strengths:\n",
            "\n",
            "[Based on the CV summary provided (Basic):]\n",
            "\n",
            "• The candidate attempted to address the main skills mentioned on the CV summary.\n",
            "• -\n",
            "• -\n",
            "\n",
            "Weaknesses:\n",
            "\n",
            "[Based on the CV summary provided:]\n",
            "\n",
            "• The candidate did not provide specific skills from the CV summary.\n",
            "• The candidate did not provide any information related to Sheheryar Ramzan's main skills.\n",
            "• The candidate did not mention any advanced machine learning techniques applied in a project.\n",
            "\n",
            "Conclusion: The candidate showed some effort in addressing the main skills listed on the CV summary but lacked specificity and depth in their responses, especially when discussing practical applications of machine learning techniques. Improvement is needed in providing detailed and relevant examples to showcase expertise effectively.\n",
            "```\n",
            "\n",
            "Formatted Performance Report saved to 'Formatted_Performance_Report.txt'.\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import fitz  # PyMuPDF for PDF handling\n",
        "import json\n",
        "\n",
        "# Initialize OpenAI API key\n",
        "openai.api_key = \"\"  \n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as pdf:\n",
        "        for page_num in range(pdf.page_count):\n",
        "            page = pdf[page_num]\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Function to collect pre-interview conditions\n",
        "def collect_pre_interview_conditions():\n",
        "    print(\"\\nBot: Before we begin the interview, I need to collect some important information.\")\n",
        "\n",
        "    employment_type = input(\"Bot: Are you applying for a freelance/consulting position or full-time employment? (F/T): \").strip().upper()\n",
        "\n",
        "    conditions = {}\n",
        "\n",
        "    if employment_type == 'F':  # Freelance/Consulting\n",
        "        print(\"\\nBot: Please provide the following information for freelance/consulting work:\")\n",
        "        conditions['employment_type'] = 'Freelance/Consulting'\n",
        "        conditions['availability_percentage'] = input(\"Bot: What is your availability percentage? (e.g., 50%, 75%, 100%): \").strip()\n",
        "        conditions['remote_rate'] = input(\"Bot: What is your hourly rate for remote work? ($): \").strip()\n",
        "        conditions['onsite_rate'] = input(\"Bot: What is your hourly rate for on-site work? ($): \").strip()\n",
        "        conditions['travel_willingness'] = input(\"Bot: Are you willing to travel? (Yes/No): \").strip()\n",
        "        conditions['other_details'] = input(\"Bot: Any other details (planned vacations, unavailable days, etc.)?: \").strip()\n",
        "\n",
        "    else:  # Full-time employment\n",
        "        print(\"\\nBot: Please provide the following information for full-time employment:\")\n",
        "        conditions['employment_type'] = 'Full-time Employment'\n",
        "        conditions['start_date'] = input(\"Bot: What is your earliest possible start date? (DD/MM/YYYY): \").strip()\n",
        "        conditions['work_hours'] = input(\"Bot: Preferred work hours per week (30/35/40): \").strip()\n",
        "        conditions['salary_expectations'] = input(\"Bot: What are your salary expectations? ($): \").strip()\n",
        "        conditions['work_location'] = input(\"Bot: Preferred work location? (Remote/On-site/Hybrid): \").strip()\n",
        "\n",
        "    return conditions\n",
        "\n",
        "# Helper function to format pre-interview conditions\n",
        "def format_pre_interview_conditions(conditions):\n",
        "    if not conditions:\n",
        "        return \"No pre-interview conditions provided.\"\n",
        "\n",
        "    formatted = f\"Employment Type: {conditions.get('employment_type', 'Not specified')}\\n\"\n",
        "\n",
        "    if conditions.get('employment_type') == 'Freelance/Consulting':\n",
        "        formatted += f\"Availability: {conditions.get('availability_percentage', 'Not specified')}\\n\"\n",
        "        formatted += f\"Remote Rate: ${conditions.get('remote_rate', 'Not specified')}/hour\\n\"\n",
        "        formatted += f\"On-site Rate: ${conditions.get('onsite_rate', 'Not specified')}/hour\\n\"\n",
        "        formatted += f\"Willing to Travel: {conditions.get('travel_willingness', 'Not specified')}\\n\"\n",
        "        formatted += f\"Other Details: {conditions.get('other_details', 'None provided')}\"\n",
        "    else:\n",
        "        formatted += f\"Start Date: {conditions.get('start_date', 'Not specified')}\\n\"\n",
        "        formatted += f\"Work Hours: {conditions.get('work_hours', 'Not specified')} hours/week\\n\"\n",
        "        formatted += f\"Salary Expectations: ${conditions.get('salary_expectations', 'Not specified')}\\n\"\n",
        "        formatted += f\"Work Location: {conditions.get('work_location', 'Not specified')}\"\n",
        "\n",
        "    return formatted\n",
        "\n",
        "# Function to generate a CV summary and identify skills\n",
        "def generate_cv_summary_and_identify_skills(cv_text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an HR assistant summarizing a CV for interview preparation.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize the following CV and identify key skills and expertise areas:\\n\\n{cv_text}\"}\n",
        "        ],\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    summary = response.choices[0].message['content'].strip()\n",
        "\n",
        "    # Extract skills\n",
        "    skills_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a system identifying the main skills for interview questions.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Based on this CV summary:\\n\\n{summary}\\n\\nList main skills.\"}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    skills = skills_response.choices[0].message['content'].strip()\n",
        "    return summary, skills.splitlines()\n",
        "\n",
        "# Function to generate progressively difficult questions based on skills and job description\n",
        "def generate_questions_by_skill(skill, job_description):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an HR assistant creating interview questions for a specific skill aligned with a job description.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"Using the job description:\\n\\n{job_description}\\n\\nGenerate a basic, intermediate, and advanced interview question for the skill '{skill}'. Format the questions as a JSON object with keys 'basic', 'intermediate', and 'advanced'.\"}\n",
        "            ],\n",
        "            max_tokens=150,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        questions_text = response.choices[0].message['content'].strip()\n",
        "\n",
        "        # Clean the response to ensure it's valid JSON\n",
        "        questions_text = questions_text.replace('\\n', ' ').strip()\n",
        "        if not questions_text.startswith('{'):\n",
        "            questions_text = '{' + questions_text\n",
        "        if not questions_text.endswith('}'):\n",
        "            questions_text = questions_text + '}'\n",
        "\n",
        "        return json.loads(questions_text)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating questions for skill '{skill}': {str(e)}\")\n",
        "        return {\n",
        "            \"basic\": f\"Can you explain your experience with {skill}?\",\n",
        "            \"intermediate\": f\"What challenges have you faced when working with {skill}?\",\n",
        "            \"advanced\": f\"How would you implement {skill} in a complex project?\"\n",
        "        }\n",
        "\n",
        "# Function to generate 12 unique questions for the interview\n",
        "def generate_unique_questions(cv_summary, skills, job_description):\n",
        "    questions = []\n",
        "    seen_question_texts = set()  # Track unique question texts\n",
        "\n",
        "    for skill in skills:\n",
        "        if len(questions) >= 12:\n",
        "            break\n",
        "\n",
        "        skill_questions = generate_questions_by_skill(skill, job_description)\n",
        "        if skill_questions:\n",
        "            for level in ['basic', 'intermediate', 'advanced']:\n",
        "                question_text = skill_questions.get(level, '')\n",
        "                if question_text and question_text not in seen_question_texts:\n",
        "                    questions.append({\n",
        "                        \"skill\": skill,\n",
        "                        \"level\": level,\n",
        "                        \"question\": question_text\n",
        "                    })\n",
        "                    seen_question_texts.add(question_text)\n",
        "\n",
        "                if len(questions) >= 12:\n",
        "                    break\n",
        "\n",
        "    return questions[:12]  # Ensure we only return 12 questions\n",
        "\n",
        "# Function to evaluate candidate answers based on the CV summary\n",
        "def evaluate_answer(answer, expected_topic):\n",
        "    evaluation_prompt = f\"Evaluate the following answer based on the topic '{expected_topic}' from the CV summary. Does it align well with the expected expertise? Answer: {answer}\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an HR assistant providing a score and feedback for the candidate's answer.\"},\n",
        "            {\"role\": \"user\", \"content\": evaluation_prompt}\n",
        "        ],\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    feedback = response.choices[0].message['content'].strip()\n",
        "\n",
        "    return feedback\n",
        "\n",
        "# Function to generate a formatted performance report\n",
        "def generate_formatted_performance_report(result_card):\n",
        "    performance_data = json.dumps(result_card, indent=2)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Using the following interview result data:\n",
        "\n",
        "{performance_data}\n",
        "\n",
        "Generate a summary in the following format:\n",
        "\n",
        "Pre-Interview Conditions:\n",
        "{format_pre_interview_conditions(result_card.get('pre_interview_conditions', {}))}\n",
        "\n",
        "Overall Result: X out of 12 points (Y%).\n",
        "\n",
        "Strengths:\n",
        "\n",
        "[Skill Area (Basic/Intermediate/Advanced):]\n",
        "\n",
        "• Bullet point 1.\n",
        "• Bullet point 2.\n",
        "• Bullet point 3.\n",
        "\n",
        "Weaknesses:\n",
        "\n",
        "[Skill Area:]\n",
        "\n",
        "• Bullet point 1.\n",
        "• Bullet point 2.\n",
        "• Bullet point 3.\n",
        "\n",
        "Conclusion: A concise conclusion summarizing strengths and weaknesses.\n",
        "\"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an HR assistant generating a formatted performance report based on interview results.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "# Function to conduct an interactive interview\n",
        "def conduct_interactive_interview(questions, cv_summary):\n",
        "    interview_responses = []\n",
        "    total_score = 0\n",
        "\n",
        "    print(\"Bot: Welcome to the interview assistant.\")\n",
        "    print(\"Bot: Let's start with a few casual questions to get to know you better.\")\n",
        "\n",
        "    name = input(\"Bot: What is your name? \").strip()\n",
        "    location = input(f\"Bot: Nice to meet you, {name}! Where are you currently located? \").strip()\n",
        "    hobbies = input(\"Bot: That's great! What are some of your hobbies? \").strip()\n",
        "\n",
        "    # Collect pre-interview conditions\n",
        "    pre_interview_conditions = collect_pre_interview_conditions()\n",
        "\n",
        "    print(\"\\nBot: Thank you for sharing! Now let's move to the interview questions.\\n\")\n",
        "\n",
        "    for i, q in enumerate(questions):\n",
        "        print(f\"Question {i + 1} ({q['level'].capitalize()} - {q['skill']}): {q['question']}\")\n",
        "        candidate_response = input(\"Your Answer: \").strip()\n",
        "        \n",
        "\n",
        "        if candidate_response.lower() == \"stop\":\n",
        "            print(\"Bot: Interview ended. Thank you for your time!\")\n",
        "            break\n",
        "\n",
        "        feedback = evaluate_answer(candidate_response, q['skill'])\n",
        "\n",
        "        interview_responses.append({\n",
        "            \"skill\": q['skill'],\n",
        "            \"level\": q['level'],\n",
        "            \"question\": q['question'],\n",
        "            \"answer\": candidate_response,\n",
        "            \"feedback\": feedback\n",
        "        })\n",
        "\n",
        "        if \"good\" in feedback.lower() or \"excellent\" in feedback.lower():\n",
        "            total_score += 1\n",
        "        elif \"average\" in feedback.lower():\n",
        "            total_score += 0.5\n",
        "\n",
        "    score_percentage = (total_score / 12) * 100\n",
        "\n",
        "    result_card = {\n",
        "        \"total_score\": total_score,\n",
        "        \"score_percentage\": score_percentage,\n",
        "        \"feedback\": interview_responses,\n",
        "        \"pre_interview_conditions\": pre_interview_conditions\n",
        "    }\n",
        "\n",
        "    print(\"\\nInterview Complete. Generating Performance Report...\\n\")\n",
        "\n",
        "    # Generate and display the formatted performance report\n",
        "    report = generate_formatted_performance_report(result_card)\n",
        "    print(report)\n",
        "\n",
        "    # Save the report to a file\n",
        "    with open(\"Formatted_Performance_Report.txt\", \"w\") as file:\n",
        "        file.write(report)\n",
        "    print(\"\\nFormatted Performance Report saved to 'Formatted_Performance_Report.txt'.\")\n",
        "\n",
        "    return result_card\n",
        "\n",
        "# Main function to conduct the entire interview process\n",
        "def full_interview_process():\n",
        "    cv_pdf_path = \"D:/Coding/Job/AI Interviewer/Sheheryar_Resume - Sheheryar Ramzan.pdf\"  # Replace with the actual CV file path\n",
        "    job_pdf_path = \"D:/Coding/Job/AI Interviewer/Machine_Learning_Job_Description.pdf\"  # Replace with the actual Job Description file path\n",
        "\n",
        "    try:\n",
        "        cv_text = extract_text_from_pdf(cv_pdf_path)\n",
        "        job_description = extract_text_from_pdf(job_pdf_path)\n",
        "\n",
        "        cv_summary, skills = generate_cv_summary_and_identify_skills(cv_text)\n",
        "        print(\"\\nDetailed CV Summary:\\n\", cv_summary)\n",
        "\n",
        "        questions = generate_unique_questions(cv_summary, skills, job_description)\n",
        "\n",
        "        if questions:\n",
        "            conduct_interactive_interview(questions, cv_summary)\n",
        "        else:\n",
        "            print(\"Interview could not proceed due to issues in question generation.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Run the full interview process\n",
        "if __name__ == \"__main__\":\n",
        "    full_interview_process()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusting to ambient noise...\n",
            "Start Speaking Listening...\n",
            "You said: hello mike testing for Google text to speech\n"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import pyaudio\n",
        "\n",
        "mic_index = 3  # Replace with the correct index from the list\n",
        "\n",
        "init_rec = sr.Recognizer()\n",
        "with sr.Microphone(device_index=mic_index) as source:\n",
        "    print(\"Adjusting to ambient noise...\")\n",
        "    init_rec.adjust_for_ambient_noise(source, duration=1)  # Adjust for noise\n",
        "    print(\"Start Speaking Listening...\")\n",
        "    audio_data = init_rec.listen(source)\n",
        "    \n",
        "try:\n",
        "    text = init_rec.recognize_google(audio_data)\n",
        "    print(\"You said:\", text)\n",
        "except sr.UnknownValueError:\n",
        "    print(\"Sorry, could not understand the audio.\")\n",
        "except sr.RequestError:\n",
        "    print(\"Could not request results. Check your internet connection.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "from io import BytesIO\n",
        "from elevenlabs.client import ElevenLabs\n",
        "\n",
        "client = ElevenLabs(\n",
        "  api_key='sk_2b3fd08d38c7744e307ea42db37b8b9529f46f94424737e8',\n",
        ")\n",
        "# Get streamed audio\n",
        "audio_stream = client.text_to_speech.convert_as_stream(\n",
        "    text=text,\n",
        "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
        "    model_id=\"eleven_multilingual_v2\"\n",
        ")\n",
        "\n",
        "# Collect the audio bytes\n",
        "audio_bytes = b\"\".join(chunk for chunk in audio_stream if isinstance(chunk, bytes))\n",
        "\n",
        "# Convert to an AudioSegment\n",
        "audio_segment = AudioSegment.from_file(BytesIO(audio_bytes), format=\"mp3\")\n",
        "\n",
        "# Play the audio\n",
        "play(audio_segment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fed",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
